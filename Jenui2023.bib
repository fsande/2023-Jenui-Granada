
BibTeX file
note            BibTeX-file
                Para ordenar ficheros bibtex con bibliografía, usar:
  
                bibtool -r /home/sande/bin/sande_bibtool.rsc -i entrada.bib -s -v -o salida.bib
  
                El fichero sande_bibtool.rsc está en /home/sande/bin/sande_bibtool.rsc
author          F. de Sande, fsande AT ull.es,
version         1.00,
date            23 April 2003,
filename        /home/sande/BIBLIOGRAFIA.bib,
address         Departamento de EIO y Computación
                Universidad de La Laguna
                38271 La Laguna, S/C de Tenerife,
                Canary Islands,
                Spain,
telephone       +34 922 318178,
FAX             +34 922 318170,
URL             http://webpages.ull.es/users/fsande,
keywords        bibliography, BibTeX, Parallel, OpenMP, MPI, Internet, Linux,,
Last update     2008/04/29 Ignorar comentarios, pretty printing
vim:ts=2:sw=2:expandtab:tw=80:fo=tcroq
vim:set fileencoding=utf8:set nu
====================================================================
@Article{Petit:Jutge:2018,
  author = {Petit, Jordi and Carmona, Josep and Cortadella, Jordi and Duch, Jordi and Giménez Omer and Mani, Anaga and Mas, Jan and Rodriguez-Carbonell, Enric },
  title = {Jutge.org: Characteristics and Experiences},
  journal = {IEEE Transactions on Learning Technologies},
  volume = {11},
  number = {3},
  pages = {321--333},
  doi = {http://dx.doi.org/10.1109/TLT.2017.2723389},
  abstract = {The IEEE Transactions on Learning Technologies},
  url = {https://ieeexplore.ieee.org/document/7968379},
  year = {2018},
}

@Misc{URL::Jutge,
  key           = {Jutge},
  title         = {{Jutge.org Home Page}},
  note          = {\href{https://jutge.org/}
                  {\small{\texttt{https://jutge.org/}}}},
}

@Misc{URL::prob,
  key           = {Jutge},
  title         = {{Jutge.org Problems}},
  note          = {\href{https://jutge.org/problems/}
                  {\small{\texttt{https://jutge.org/problems/}}}},
}

@Misc{ULL:2022:GD,
  author        = {Universidad de La Laguna},
  institution   = {Universidad de La Laguna},
  title         = {Guía Docente de {I}nformática {B}ásica},
  year          = {2022},
  note          = {\href{https://www.ull.es/apps/guias/guias/view_guide/34182/}
                  {\small{\texttt{https://www.ull.es/apps/guias/guias/
                    \\view\_guide/34182}}}},
}

@Article{Zhang:2020:chatgpt,
  title={{ChatGPT}: A Task-Oriented Dialogue System Based on Pre-trained Language Model},
  author={Zhang, Xingxing and Zhang, Jinchao and Eskenazi, Maxine},
  journal={arXiv preprint arXiv:2012.16641},
  year={2020}
}

@Article{Castelvecchi:2022:ACaA,
  author = {Castelvecchi, Davide},
  title = {Are {ChatGPT} and {AlphaCode} going to replace programmers?},
  journal = {Nature (London)},
  issn = {0028-0836},
  year = {2022},
  month = {12},
  doi = {10.1038/d41586-022-04383-z},
  language = {eng},
  address = {England},
}

@Article{Bao:2021:CAR,
  title={Conversational AI: A Review of the State of the Art},
  author={Bao, Siqi and Zhang, Jinchao and Zhang, Xingxing and Eskenazi, Maxine},
  journal={arXiv preprint arXiv:2104.07720},
  year={2021}
}

@misc{Friedman:2021:IGC,
  title={Introducing {GitHub Copilot}: your {AI} pair programmer},
  author={Friedman, Nat},
  year={2021}
}

@Article{Chen:2021:ELL,
  title={Evaluating large language models trained on code},
  author={Chen, Mark and Tworek, Jerry and Jun, Heewoo and Yuan, Qiming and Pinto, Henrique Ponde de Oliveira and Kaplan, Jared and Edwards, Harri and Burda, Yuri and Joseph, Nicholas and Brockman, Greg},
  journal={arXiv preprint arXiv:2107.03374},
  year={2021}
}

@Article{Li:2022:CCG,
  author = {Yujia Li and David Choi and Junyoung Chung and Nate Kushman and Julian Schrittwieser et~al.},
  title = {Competition-level code generation with {AlphaCode}},
  journal = {Science},
  volume = {378},
  number = {6624},
  pages = {1092-1097},
  year = {2022},
  doi = {10.1126/science.abq1158},
  URL = {https://www.science.org/doi/abs/10.1126/science.abq1158},
  eprint = {https://www.science.org/doi/pdf/10.1126/science.abq1158},
  abstract = {Programming is a powerful and ubiquitous problem-solving tool. 
              Systems that can assist programmers or even generate programs themselves could make programming more productive and accessible. 
              Recent transformer-based neural network models show impressive code generation abilities yet still perform poorly on more complex tasks requiring problem-solving skills, 
              such as competitive programming problems. 
              Here, we introduce AlphaCode, a system for code generation that achieved an average ranking in the top 54.3\% in simulated evaluations 
              on recent programming competitions on the Codeforces platform. 
              AlphaCode solves problems by generating millions of diverse programs using specially trained transformer-based networks and then 
              filtering and clustering those programs to a maximum of just 10 submissions. 
              This result marks the first time an artificial intelligence system has performed competitively in programming competitions. 
              Computer programming competitions are popular tests among programmers that require critical thinking informed by experience and creating solutions 
              to unforeseen problems, both of which are key aspects of human intelligence but challenging to mimic by machine learning models. 
              Using self-supervised learning and an encoder-decoder transformer architecture, Li et al. developed AlphaCode, a deep-learning model 
              that can achieve approximately human-level performance on the Codeforces platform, which regularly hosts these competitions and attracts numerous 
              participants worldwide (see the Perspective by Kolter). The development of such coding platforms could have a huge impact on programmers’ productivity. 
              It may even change the culture of programming by shifting human work to formulating problems, with machine learning being the main one 
              responsible for generating and executing codes. —YS Modern machine learning systems can achieve average human-level performance in popular competitive programming contests.},
}

@Misc{Google::GSG,
  key           = {Google},
  author        = {Google}, 
  year          = {2023},
  title         = {{Google C++ Style Guide}},
  note          = {\href{https://google.github.io/styleguide/cppguide.html}
                  {\small{\texttt{https://google.github.io/styleguide/
                          \\cppguide.html}}}},
}

@Article{Perez:2022:FBM,
  title         = {``Funciona muy bien, pero no es magia'': así es {ChatGPT}, la nueva inteligencia artificial que supera límites},
  author        = {Jordi Pérez Colomé},
  journal       = {El País},
  day           = {7},
  month         = {diciembre},
  year          = {2022},
  note          = {\href{https://elpais.com/tecnologia/2022-12-07/funciona-muy-bien-pero-no-es-magia-asi-es-chatgpt-la-nueva-inteligencia-artificial-que-supera-limites.html}
                  {\small{\texttt{https://elpais.com/}}}},
}

@Article{Cassidy:2023:AUR,
  title         = {Australian universities to return to 'pen and paper' exams after students caught using {AI} to write essays},
  author        = {Caitlin Cassidy},
  journal       = {The Guardian},
  day           = {10},
  month         = {enero},
  year          = {2023},
  note          = {\href{https://www.theguardian.com/australia-news/2023/jan/10/universities-to-return-to-pen-and-paper-exams-after-students-caught-using-ai-to-write-essays}
                  {\small{\texttt{https://www.theguardian.com/}}}},
}

@article{Dakhel:2022:GCA,
  title         = {{GitHub Copilot AI pair programmer: Asset or Liability?}},
  author        = {Dakhel, Arghavan Moradi and Majdinasab, Vahid and Nikanjam, Amin and Khomh, Foutse and Desmarais, Michel C and Ming, Zhen and Jiang},
  year          = {2022},
  abstract = {Automatic program synthesis is a long-lasting dream in software engineering.
Recently, a promising Deep Learning (DL) based solution, called Copilot, has
been proposed by Open AI and Microsoft as an industrial product. Although some
studies evaluate the correctness of Copilot solutions and report its issues,
more empirical evaluations are necessary to understand how developers can
benefit from it effectively. In this paper, we study the capabilities of
Copilot in two different programming tasks: (1) generating (and reproducing)
correct and efficient solutions for fundamental algorithmic problems, and (2)
comparing Copilot's proposed solutions with those of human programmers on a set
of programming tasks. For the former, we assess the performance and
functionality of Copilot in solving selected fundamental problems in computer
science, like sorting and implementing basic data structures. In the latter, a
dataset of programming problems with human-provided solutions is used. The
results show that Copilot is capable of providing solutions for almost all
fundamental algorithmic problems, however, some solutions are buggy and
non-reproducible. Moreover, Copilot has some difficulties in combining multiple
methods to generate a solution. Comparing Copilot to humans, our results show
that the correct ratio of human solutions is greater than Copilot's correct
ratio, while the buggy solutions generated by Copilot require less effort to be
repaired. While Copilot shows limitations as an assistant for developers
especially in advanced programming tasks, as highlighted in this study and
previous ones, it can generate preliminary solutions for basic programming
tasks.},
  copyright = {http://arxiv.org/licenses/nonexclusive-distrib/1.0},
  language = {eng},
}

@article{Nguyen:2022:AnEE,
  title   = {{An Empirical Evaluation of GitHub Copilot's Code Suggestions}},
  author  = {Nhan Ton Nguyen and Sarah Nadi},
  journal = {2022 IEEE/ACM 19th International Conference on Mining Software Repositories (MSR)},
  year    = {2022},
  pages   = {1-5}
}

@InProceedings{Kung:2022:PCU,
  author        = {Tiffany H. Kung et~al.},
  title         = {{Performance of ChatGPT on USMLE: Potential for AI-Assisted Medical Education Using Large Language Models}},
  booktitle     = {NPJ Digit. Med.},
  year          = {2022},
  doi           = {https://doi.org/10.1101/2022.12.19.22283643},
}

@article{Floridi:2020:GPT-3,
  author = {Floridi, Luciano and Chiriatti, Massimo},
  title = {{GPT-3}: Its Nature, Scope, Limits, and Consequences},
  year = {2020},
  issue_date = {Dec 2020},
  publisher = {Kluwer Academic Publishers},
  address = {USA},
  volume = {30},
  number = {4},
  issn = {0924-6495},
  url = {https://doi.org/10.1007/s11023-020-09548-1},
  doi = {10.1007/s11023-020-09548-1},
  journal = {Minds Mach.},
  month = {dec},
  pages = {681–694},
  numpages = {14},
  keywords = {GPT-3, Automation, Turing Test, Irreversibility, Artificial Intelligence, Semantics},
  abstract = {In this commentary, we discuss the nature of reversible and irreversible questions, that is, 
              questions that may enable one to identify the nature of the source of their answers. 
              We then introduce GPT-3, a third-generation, autoregressive language model that uses deep 
              learning to produce human-like texts, and use the previous distinction to analyse it. 
              We expand the analysis to present three tests based on mathematical, semantic (that is, the Turing Test), 
              and ethical questions and show that GPT-3 is not designed to pass any of them. 
              This is a reminder that GPT-3 does not do what it is not supposed to do, and that any interpretation of GPT-3 
              as the beginning of the emergence of a general form of artificial intelligence is merely uninformed science fiction. 
              We conclude by outlining some of the significant consequences of the industrialisation of automatic and cheap production of good, semantic artefacts.},
}

@article{Welsh:2023:TEoP,
  title = {The End of Programming},
  author = {Welsh, Matt},
  journal = {Communications of the ACM},
  year = {2023},
  volume = {66},
  number = {1},
  pages = {34--35},
  issn = {0001-0782},
  abstract = {The end of classical computer science is coming, and most of us are dinosaurs waiting for the meteor to hit.},
  language = {eng},
}

%XXX 
% 
